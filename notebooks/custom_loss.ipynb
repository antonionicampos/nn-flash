{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from itertools import product\n",
    "from src.data.handlers import DataLoader\n",
    "from src.models.regression import MeanSquaredErrorWithSoftConstraint, NeuralNet\n",
    "from src.utils import denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_K_to_XY(outputs, inputs):\n",
    "    K = outputs[:, :-1]\n",
    "    V = outputs[:, -1:]\n",
    "    Z = inputs[:, :-2]\n",
    "    L = 1 - V\n",
    "    X = Z / (L + V * K)\n",
    "    Y = K * X\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def train_model(datasets, minmax, log=False, **kwargs):\n",
    "    hidden_units = kwargs[\"hidden_units\"]\n",
    "\n",
    "    activation = \"relu\"\n",
    "    batch_size = 32\n",
    "    epochs = 200\n",
    "    lr = 0.001\n",
    "    lambda_ = kwargs[\"lambda\"]\n",
    "\n",
    "    # 10% das épocas com a restrição\n",
    "\n",
    "    train_log = \"Epoch: {:04d}, train loss: {:.5f}, valid loss: {:.5f}\"\n",
    "    # summ_xi_hat = np.zeros((10,))\n",
    "    # summ_yi_hat = np.zeros((10,))\n",
    "\n",
    "    for i, (train, valid, minmax_vals) in enumerate(zip(datasets[\"train\"], datasets[\"valid\"], minmax)):\n",
    "        min_vals, max_vals = minmax_vals\n",
    "        min_vals = tf.convert_to_tensor(min_vals, dtype=tf.float32)\n",
    "        max_vals = tf.convert_to_tensor(max_vals, dtype=tf.float32)\n",
    "        x_train = tf.convert_to_tensor(train[\"features\"], dtype=tf.float32)\n",
    "        y_train = tf.convert_to_tensor(train[\"targets\"], dtype=tf.float32)\n",
    "        x_valid = tf.convert_to_tensor(valid[\"features\"], dtype=tf.float32)\n",
    "        y_valid = tf.convert_to_tensor(valid[\"targets\"], dtype=tf.float32)\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "\n",
    "        model = NeuralNet(hidden_units, activation)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        loss_func = MeanSquaredErrorWithSoftConstraint(lambda_=lambda_)\n",
    "\n",
    "        train_losses, valid_losses = [], []\n",
    "        for epoch in range(epochs):\n",
    "            for x_batch_train, y_batch_train in train_dataset:\n",
    "\n",
    "                # Record operations\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_hat = model(x_batch_train, training=True)\n",
    "                    loss_val = loss_func(y_batch_train, y_hat, x_batch_train, min_vals, max_vals)\n",
    "\n",
    "                # Grads dloss/dwij\n",
    "                grads = tape.gradient(loss_val, model.trainable_weights)\n",
    "\n",
    "                # Optimizer using grads\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "                # Validation loss\n",
    "                loss_val = loss_func(y_batch_train, y_hat, x_batch_train, min_vals, max_vals)\n",
    "\n",
    "            y_hat_train = model(x_train)\n",
    "            y_hat_valid = model(x_valid)\n",
    "            train_loss = loss_func(y_train, y_hat_train, x_train, min_vals, max_vals)\n",
    "            valid_loss = loss_func(y_valid, y_hat_valid, x_valid, min_vals, max_vals)\n",
    "\n",
    "            train_losses.append(float(train_loss))\n",
    "            valid_losses.append(float(valid_loss))\n",
    "\n",
    "            if log and (epoch + 1) % 100 == 0:\n",
    "                print(train_log.format(epoch + 1, float(train_loss), float(valid_loss)))\n",
    "        break\n",
    "\n",
    "    y_hat_valid = model(x_valid)\n",
    "\n",
    "    y_pred = denorm(y_hat_valid, min_vals, max_vals)\n",
    "    xi_pred, yi_pred = convert_K_to_XY(y_pred, x_valid)\n",
    "\n",
    "    # summ_xi_hat[i] = xi_pred.numpy().sum(axis=-1).mean(axis=-1)\n",
    "    # summ_yi_hat[i] = yi_pred.numpy().sum(axis=-1).mean(axis=-1)\n",
    "\n",
    "    return {\n",
    "        **kwargs,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"valid_losses\": valid_losses,\n",
    "        \"summ_xi_hat\": xi_pred.numpy().sum(axis=-1).mean(),\n",
    "        \"summ_yi_hat\": yi_pred.numpy().sum(axis=-1).mean(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader()\n",
    "datasets, minmax = dl.load_cross_validation_datasets(problem=\"regression\", samples_per_composition=30)\n",
    "\n",
    "params = {\"hidden_layers\": [3, 4, 5, 6, 7], \"hidden_units\": [128, 256, 512], \"lambda\": [0.0, 1e-3, 1e-2, 1e-1]}\n",
    "\n",
    "results = []\n",
    "hyperparameters = list(product(*[vals for vals in params.values()]))\n",
    "xy = np.zeros((len(hyperparameters), 2))\n",
    "for i, (hidden_units, neurons, lambda_) in enumerate(hyperparameters):\n",
    "    hparams = {\"hidden_units\": [neurons for _ in range(hidden_units)], \"lambda\": lambda_}\n",
    "    start = datetime.now()\n",
    "    r = train_model(datasets, minmax, **hparams)\n",
    "    end = datetime.now()\n",
    "\n",
    "    results.append(r)\n",
    "    xy[i, 0] = r[\"summ_xi_hat\"]\n",
    "    xy[i, 1] = r[\"summ_yi_hat\"]\n",
    "\n",
    "    print(f\"training model: {i+1}/{len(hyperparameters)}, elapsed time: {end - start}\")\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = pd.DataFrame(hyperparameters).sort_values([2, 0, 1])\n",
    "sorted_idx = pd.DataFrame(hyperparameters).sort_values([2, 0, 1]).index\n",
    "\n",
    "losses = np.array([r[\"valid_losses\"][-1] for r in results])\n",
    "\n",
    "f, axs = plt.subplots(2, 1, figsize=(12, 5), sharex=True)\n",
    "axs[0].errorbar(np.arange(len(hyperparameters)), xy[sorted_idx, 0], fmt=\"o-\", label=\"$\\sum \\widehat{x_i}$\")\n",
    "axs[0].errorbar(np.arange(len(hyperparameters)), xy[sorted_idx, 1], fmt=\"o-\", label=\"$\\sum \\widehat{y_i}$\")\n",
    "axs[0].axhline(1.0, ls=\"--\")\n",
    "axs[0].axvspan(11.5, 23.5, alpha=0.2)\n",
    "\n",
    "# axs[0].set_ylim(bottom=0.15)\n",
    "axs[0].text(-1.2, 0.94, \"$\\lambda = 0.0$\", fontsize=14)\n",
    "axs[0].text(11.8, 0.94, \"$\\lambda = 0.1$\", fontsize=14)\n",
    "axs[0].text(23.8, 0.94, \"$\\lambda = 100.0$\", fontsize=14)\n",
    "# axs[0].set_xticks(np.arange(len(hyperparameters)), hyperparameters, rotation=\"vertical\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(losses[sorted_idx], \"o-\", label=\"loss\")\n",
    "axs[1].set_xticks(np.arange(len(hyperparameters)), hyperparameters.to_records(index=False), rotation=\"vertical\")\n",
    "axs[1].axvspan(11.5, 23.5, alpha=0.2)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_idx = -3\n",
    "train_losses, valid_losses = results[model_idx][\"train_losses\"],results[model_idx][\"valid_losses\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(np.arange(len(train_losses)), train_losses, label=\"train\")\n",
    "ax.plot(np.arange(len(valid_losses)), valid_losses, label=\"valid\")\n",
    "ax.grid()\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
