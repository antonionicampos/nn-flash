{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import ticker\n",
    "from scipy.stats import gmean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from src.data.synthetic_gen import DataLoader\n",
    "from src.models.classification import NeuralNetClassifier\n",
    "from src.models.classification.evaluate_models import ClassificationAnalysis\n",
    "from src.models.classification.train_models import ClassificationTraining\n",
    "from src.visualization.styles.formatting import errorbar_kwargs\n",
    "from src.utils.constants import K_FOLDS\n",
    "\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Rede Neural #8, ID: 23\n",
      "    params: {'hidden_units': [64, 64], 'activation': 'relu'}\n",
      "    opt:    {'lr': 0.001, 'epochs': 500, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "classifier_model_name = \"Rede Neural #8\"\n",
    "generator_model_name = \"WGAN #11\"\n",
    "\n",
    "training = ClassificationTraining()\n",
    "analysis = ClassificationAnalysis()\n",
    "\n",
    "results = training.load_training_models()\n",
    "indices = analysis.load_performance_indices()\n",
    "\n",
    "output = [out for out in results[\"outputs\"] if out[\"model_name\"] == classifier_model_name][0]\n",
    "model_id = [i for i, out in enumerate(results[\"outputs\"]) if out[\"model_name\"] == classifier_model_name][0]\n",
    "\n",
    "print(f\"Modelo: {output['model_name']}, ID: {model_id}\")\n",
    "print(\"    params:\", output[\"params\"])\n",
    "print(\"    opt:   \", output[\"opt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training best neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - categorical_accuracy: 0.4920 - loss: 1.0208 - val_categorical_accuracy: 0.6545 - val_loss: 0.7757 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - categorical_accuracy: 0.6695 - loss: 0.7151 - val_categorical_accuracy: 0.6909 - val_loss: 0.6545 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - categorical_accuracy: 0.6922 - loss: 0.6312 - val_categorical_accuracy: 0.7636 - val_loss: 0.6002 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - categorical_accuracy: 0.7133 - loss: 0.5778 - val_categorical_accuracy: 0.8000 - val_loss: 0.5541 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - categorical_accuracy: 0.7297 - loss: 0.5439 - val_categorical_accuracy: 0.8000 - val_loss: 0.5230 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - categorical_accuracy: 0.7480 - loss: 0.5272 - val_categorical_accuracy: 0.8545 - val_loss: 0.5041 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - categorical_accuracy: 0.7823 - loss: 0.4973 - val_categorical_accuracy: 0.8545 - val_loss: 0.4810 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - categorical_accuracy: 0.7914 - loss: 0.4568 - val_categorical_accuracy: 0.8727 - val_loss: 0.4563 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - categorical_accuracy: 0.8186 - loss: 0.4393 - val_categorical_accuracy: 0.8909 - val_loss: 0.4544 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - categorical_accuracy: 0.8233 - loss: 0.4308 - val_categorical_accuracy: 0.8545 - val_loss: 0.4245 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - categorical_accuracy: 0.8223 - loss: 0.4054 - val_categorical_accuracy: 0.8909 - val_loss: 0.4183 - learning_rate: 0.0010\n",
      "Epoch 12/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - categorical_accuracy: 0.8267 - loss: 0.3928 - val_categorical_accuracy: 0.8545 - val_loss: 0.4034 - learning_rate: 0.0010\n",
      "Epoch 13/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - categorical_accuracy: 0.8287 - loss: 0.3855 - val_categorical_accuracy: 0.8909 - val_loss: 0.3937 - learning_rate: 0.0010\n",
      "Epoch 14/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - categorical_accuracy: 0.8578 - loss: 0.3599 - val_categorical_accuracy: 0.8727 - val_loss: 0.4353 - learning_rate: 0.0010\n",
      "Epoch 15/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - categorical_accuracy: 0.8398 - loss: 0.3775 - val_categorical_accuracy: 0.8909 - val_loss: 0.3829 - learning_rate: 0.0010\n",
      "Epoch 16/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - categorical_accuracy: 0.8867 - loss: 0.3222 - val_categorical_accuracy: 0.9091 - val_loss: 0.4153 - learning_rate: 0.0010\n",
      "Epoch 17/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - categorical_accuracy: 0.8673 - loss: 0.3507 - val_categorical_accuracy: 0.8909 - val_loss: 0.3705 - learning_rate: 0.0010\n",
      "Epoch 18/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.8751 - loss: 0.3068 - val_categorical_accuracy: 0.8727 - val_loss: 0.3871 - learning_rate: 0.0010\n",
      "Epoch 19/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - categorical_accuracy: 0.8845 - loss: 0.3016 - val_categorical_accuracy: 0.9091 - val_loss: 0.3780 - learning_rate: 0.0010\n",
      "Epoch 20/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - categorical_accuracy: 0.9060 - loss: 0.2765 - val_categorical_accuracy: 0.9273 - val_loss: 0.3770 - learning_rate: 0.0010\n",
      "Epoch 21/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - categorical_accuracy: 0.8860 - loss: 0.2920 - val_categorical_accuracy: 0.8909 - val_loss: 0.3500 - learning_rate: 0.0010\n",
      "Epoch 22/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - categorical_accuracy: 0.9033 - loss: 0.2723 - val_categorical_accuracy: 0.8909 - val_loss: 0.3501 - learning_rate: 0.0010\n",
      "Epoch 23/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - categorical_accuracy: 0.9018 - loss: 0.2602 - val_categorical_accuracy: 0.8909 - val_loss: 0.3369 - learning_rate: 0.0010\n",
      "Epoch 24/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - categorical_accuracy: 0.9030 - loss: 0.2488 - val_categorical_accuracy: 0.8727 - val_loss: 0.3790 - learning_rate: 0.0010\n",
      "Epoch 25/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - categorical_accuracy: 0.9016 - loss: 0.2645 - val_categorical_accuracy: 0.8909 - val_loss: 0.3292 - learning_rate: 0.0010\n",
      "Epoch 26/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - categorical_accuracy: 0.9103 - loss: 0.2494 - val_categorical_accuracy: 0.9091 - val_loss: 0.3512 - learning_rate: 0.0010\n",
      "Epoch 27/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - categorical_accuracy: 0.9226 - loss: 0.2371 - val_categorical_accuracy: 0.8909 - val_loss: 0.3317 - learning_rate: 0.0010\n",
      "Epoch 28/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9071 - loss: 0.2452 - val_categorical_accuracy: 0.8545 - val_loss: 0.3855 - learning_rate: 0.0010\n",
      "Epoch 29/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - categorical_accuracy: 0.8956 - loss: 0.2452 - val_categorical_accuracy: 0.8909 - val_loss: 0.3246 - learning_rate: 0.0010\n",
      "Epoch 30/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - categorical_accuracy: 0.9261 - loss: 0.2222 - val_categorical_accuracy: 0.9455 - val_loss: 0.3550 - learning_rate: 0.0010\n",
      "Epoch 31/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - categorical_accuracy: 0.9195 - loss: 0.2259 - val_categorical_accuracy: 0.8909 - val_loss: 0.3489 - learning_rate: 0.0010\n",
      "Epoch 32/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - categorical_accuracy: 0.9209 - loss: 0.2159 - val_categorical_accuracy: 0.9091 - val_loss: 0.3037 - learning_rate: 0.0010\n",
      "Epoch 33/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - categorical_accuracy: 0.9289 - loss: 0.2013 - val_categorical_accuracy: 0.9091 - val_loss: 0.3153 - learning_rate: 0.0010\n",
      "Epoch 34/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - categorical_accuracy: 0.9098 - loss: 0.2342 - val_categorical_accuracy: 0.9273 - val_loss: 0.3017 - learning_rate: 0.0010\n",
      "Epoch 35/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - categorical_accuracy: 0.9198 - loss: 0.2154 - val_categorical_accuracy: 0.8909 - val_loss: 0.3210 - learning_rate: 0.0010\n",
      "Epoch 36/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.9155 - loss: 0.2204 - val_categorical_accuracy: 0.9091 - val_loss: 0.2980 - learning_rate: 0.0010\n",
      "Epoch 37/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - categorical_accuracy: 0.9314 - loss: 0.1957 - val_categorical_accuracy: 0.9091 - val_loss: 0.2948 - learning_rate: 0.0010\n",
      "Epoch 38/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - categorical_accuracy: 0.9223 - loss: 0.2010 - val_categorical_accuracy: 0.9273 - val_loss: 0.3062 - learning_rate: 0.0010\n",
      "Epoch 39/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - categorical_accuracy: 0.9382 - loss: 0.1905 - val_categorical_accuracy: 0.9273 - val_loss: 0.3033 - learning_rate: 0.0010\n",
      "Epoch 40/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - categorical_accuracy: 0.9379 - loss: 0.1801 - val_categorical_accuracy: 0.9091 - val_loss: 0.3042 - learning_rate: 0.0010\n",
      "Epoch 41/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - categorical_accuracy: 0.9267 - loss: 0.1996 - val_categorical_accuracy: 0.9091 - val_loss: 0.2881 - learning_rate: 0.0010\n",
      "Epoch 42/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - categorical_accuracy: 0.9243 - loss: 0.1936 - val_categorical_accuracy: 0.9273 - val_loss: 0.2794 - learning_rate: 0.0010\n",
      "Epoch 43/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - categorical_accuracy: 0.9384 - loss: 0.1697 - val_categorical_accuracy: 0.9273 - val_loss: 0.2825 - learning_rate: 0.0010\n",
      "Epoch 44/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - categorical_accuracy: 0.9407 - loss: 0.1801 - val_categorical_accuracy: 0.8909 - val_loss: 0.2830 - learning_rate: 0.0010\n",
      "Epoch 45/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - categorical_accuracy: 0.9351 - loss: 0.1807 - val_categorical_accuracy: 0.9091 - val_loss: 0.2778 - learning_rate: 0.0010\n",
      "Epoch 46/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - categorical_accuracy: 0.9427 - loss: 0.1660 - val_categorical_accuracy: 0.9273 - val_loss: 0.2989 - learning_rate: 0.0010\n",
      "Epoch 47/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9385 - loss: 0.1762 - val_categorical_accuracy: 0.9091 - val_loss: 0.2799 - learning_rate: 0.0010\n",
      "Epoch 48/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - categorical_accuracy: 0.9426 - loss: 0.1598 - val_categorical_accuracy: 0.9091 - val_loss: 0.2787 - learning_rate: 0.0010\n",
      "Epoch 49/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - categorical_accuracy: 0.9426 - loss: 0.1540 - val_categorical_accuracy: 0.9091 - val_loss: 0.3042 - learning_rate: 0.0010\n",
      "Epoch 50/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - categorical_accuracy: 0.9466 - loss: 0.1607 - val_categorical_accuracy: 0.9273 - val_loss: 0.3089 - learning_rate: 0.0010\n",
      "Epoch 51/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - categorical_accuracy: 0.9414 - loss: 0.1722 - val_categorical_accuracy: 0.9091 - val_loss: 0.2769 - learning_rate: 0.0010\n",
      "Epoch 52/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - categorical_accuracy: 0.9421 - loss: 0.1582 - val_categorical_accuracy: 0.9273 - val_loss: 0.2753 - learning_rate: 0.0010\n",
      "Epoch 53/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.9205 - loss: 0.1907 - val_categorical_accuracy: 0.9273 - val_loss: 0.2716 - learning_rate: 0.0010\n",
      "Epoch 54/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - categorical_accuracy: 0.9532 - loss: 0.1448 - val_categorical_accuracy: 0.9091 - val_loss: 0.2775 - learning_rate: 0.0010\n",
      "Epoch 55/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - categorical_accuracy: 0.9440 - loss: 0.1556 - val_categorical_accuracy: 0.8909 - val_loss: 0.3176 - learning_rate: 0.0010\n",
      "Epoch 56/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - categorical_accuracy: 0.9396 - loss: 0.1653 - val_categorical_accuracy: 0.8727 - val_loss: 0.3012 - learning_rate: 0.0010\n",
      "Epoch 57/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - categorical_accuracy: 0.9164 - loss: 0.2018 - val_categorical_accuracy: 0.9273 - val_loss: 0.2624 - learning_rate: 0.0010\n",
      "Epoch 58/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - categorical_accuracy: 0.9344 - loss: 0.1655 - val_categorical_accuracy: 0.8909 - val_loss: 0.2822 - learning_rate: 0.0010\n",
      "Epoch 59/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - categorical_accuracy: 0.9527 - loss: 0.1431 - val_categorical_accuracy: 0.9091 - val_loss: 0.2723 - learning_rate: 0.0010\n",
      "Epoch 60/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - categorical_accuracy: 0.9473 - loss: 0.1462 - val_categorical_accuracy: 0.9273 - val_loss: 0.2798 - learning_rate: 0.0010\n",
      "Epoch 61/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.9438 - loss: 0.1461 - val_categorical_accuracy: 0.9273 - val_loss: 0.2618 - learning_rate: 0.0010\n",
      "Epoch 62/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - categorical_accuracy: 0.9389 - loss: 0.1552 - val_categorical_accuracy: 0.9273 - val_loss: 0.2739 - learning_rate: 0.0010\n",
      "Epoch 63/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - categorical_accuracy: 0.9459 - loss: 0.1392 - val_categorical_accuracy: 0.9273 - val_loss: 0.2928 - learning_rate: 0.0010\n",
      "Epoch 64/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - categorical_accuracy: 0.9507 - loss: 0.1441 - val_categorical_accuracy: 0.9273 - val_loss: 0.2547 - learning_rate: 0.0010\n",
      "Epoch 65/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - categorical_accuracy: 0.9492 - loss: 0.1392 - val_categorical_accuracy: 0.9455 - val_loss: 0.2790 - learning_rate: 0.0010\n",
      "Epoch 66/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - categorical_accuracy: 0.9320 - loss: 0.1760 - val_categorical_accuracy: 0.9091 - val_loss: 0.2527 - learning_rate: 0.0010\n",
      "Epoch 67/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - categorical_accuracy: 0.9496 - loss: 0.1385 - val_categorical_accuracy: 0.9273 - val_loss: 0.2560 - learning_rate: 0.0010\n",
      "Epoch 68/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - categorical_accuracy: 0.9454 - loss: 0.1429 - val_categorical_accuracy: 0.9091 - val_loss: 0.2551 - learning_rate: 0.0010\n",
      "Epoch 69/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - categorical_accuracy: 0.9304 - loss: 0.1740 - val_categorical_accuracy: 0.9091 - val_loss: 0.2523 - learning_rate: 0.0010\n",
      "Epoch 70/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9506 - loss: 0.1293 - val_categorical_accuracy: 0.9273 - val_loss: 0.2611 - learning_rate: 0.0010\n",
      "Epoch 71/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - categorical_accuracy: 0.9377 - loss: 0.1628 - val_categorical_accuracy: 0.9455 - val_loss: 0.2762 - learning_rate: 0.0010\n",
      "Epoch 72/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - categorical_accuracy: 0.9448 - loss: 0.1430 - val_categorical_accuracy: 0.9273 - val_loss: 0.2539 - learning_rate: 0.0010\n",
      "Epoch 73/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - categorical_accuracy: 0.9470 - loss: 0.1385 - val_categorical_accuracy: 0.9273 - val_loss: 0.2370 - learning_rate: 0.0010\n",
      "Epoch 74/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - categorical_accuracy: 0.9582 - loss: 0.1259 - val_categorical_accuracy: 0.9273 - val_loss: 0.3225 - learning_rate: 0.0010\n",
      "Epoch 75/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - categorical_accuracy: 0.9487 - loss: 0.1435 - val_categorical_accuracy: 0.9273 - val_loss: 0.2382 - learning_rate: 0.0010\n",
      "Epoch 76/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - categorical_accuracy: 0.9542 - loss: 0.1304 - val_categorical_accuracy: 0.9455 - val_loss: 0.2532 - learning_rate: 0.0010\n",
      "Epoch 77/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - categorical_accuracy: 0.9680 - loss: 0.1175 - val_categorical_accuracy: 0.9455 - val_loss: 0.2914 - learning_rate: 0.0010\n",
      "Epoch 78/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - categorical_accuracy: 0.9600 - loss: 0.1206 - val_categorical_accuracy: 0.9273 - val_loss: 0.2535 - learning_rate: 0.0010\n",
      "Epoch 79/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - categorical_accuracy: 0.9492 - loss: 0.1383 - val_categorical_accuracy: 0.9455 - val_loss: 0.2553 - learning_rate: 0.0010\n",
      "Epoch 80/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.9535 - loss: 0.1240 - val_categorical_accuracy: 0.9455 - val_loss: 0.2788 - learning_rate: 0.0010\n",
      "Epoch 81/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9390 - loss: 0.1518 - val_categorical_accuracy: 0.9455 - val_loss: 0.2330 - learning_rate: 0.0010\n",
      "Epoch 82/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - categorical_accuracy: 0.9585 - loss: 0.1231 - val_categorical_accuracy: 0.9455 - val_loss: 0.2471 - learning_rate: 0.0010\n",
      "Epoch 83/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - categorical_accuracy: 0.9641 - loss: 0.1070 - val_categorical_accuracy: 0.9455 - val_loss: 0.2442 - learning_rate: 0.0010\n",
      "Epoch 84/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - categorical_accuracy: 0.9594 - loss: 0.1118 - val_categorical_accuracy: 0.9273 - val_loss: 0.2619 - learning_rate: 0.0010\n",
      "Epoch 85/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - categorical_accuracy: 0.9585 - loss: 0.1164 - val_categorical_accuracy: 0.9273 - val_loss: 0.2217 - learning_rate: 0.0010\n",
      "Epoch 86/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - categorical_accuracy: 0.9531 - loss: 0.1225 - val_categorical_accuracy: 0.8909 - val_loss: 0.2811 - learning_rate: 0.0010\n",
      "Epoch 87/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9562 - loss: 0.1194 - val_categorical_accuracy: 0.8727 - val_loss: 0.2518 - learning_rate: 0.0010\n",
      "Epoch 88/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - categorical_accuracy: 0.9502 - loss: 0.1305 - val_categorical_accuracy: 0.9455 - val_loss: 0.2157 - learning_rate: 0.0010\n",
      "Epoch 89/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - categorical_accuracy: 0.9522 - loss: 0.1178 - val_categorical_accuracy: 0.9273 - val_loss: 0.2408 - learning_rate: 0.0010\n",
      "Epoch 90/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - categorical_accuracy: 0.9587 - loss: 0.1157 - val_categorical_accuracy: 0.9273 - val_loss: 0.2520 - learning_rate: 0.0010\n",
      "Epoch 91/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - categorical_accuracy: 0.9596 - loss: 0.1129 - val_categorical_accuracy: 0.9455 - val_loss: 0.2227 - learning_rate: 0.0010\n",
      "Epoch 92/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - categorical_accuracy: 0.9456 - loss: 0.1301 - val_categorical_accuracy: 0.9273 - val_loss: 0.2276 - learning_rate: 0.0010\n",
      "Epoch 93/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - categorical_accuracy: 0.9585 - loss: 0.1133 - val_categorical_accuracy: 0.9273 - val_loss: 0.2269 - learning_rate: 0.0010\n",
      "Epoch 94/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - categorical_accuracy: 0.9513 - loss: 0.1168 - val_categorical_accuracy: 0.9091 - val_loss: 0.2842 - learning_rate: 0.0010\n",
      "Epoch 95/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - categorical_accuracy: 0.9441 - loss: 0.1299 - val_categorical_accuracy: 0.9273 - val_loss: 0.2099 - learning_rate: 0.0010\n",
      "Epoch 96/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9521 - loss: 0.1184 - val_categorical_accuracy: 0.9455 - val_loss: 0.2389 - learning_rate: 0.0010\n",
      "Epoch 97/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - categorical_accuracy: 0.9384 - loss: 0.1605 - val_categorical_accuracy: 0.8727 - val_loss: 0.3009 - learning_rate: 0.0010\n",
      "Epoch 98/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - categorical_accuracy: 0.9483 - loss: 0.1316 - val_categorical_accuracy: 0.9273 - val_loss: 0.2230 - learning_rate: 0.0010\n",
      "Epoch 99/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.9477 - loss: 0.1271 - val_categorical_accuracy: 0.9455 - val_loss: 0.2825 - learning_rate: 0.0010\n",
      "Epoch 100/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - categorical_accuracy: 0.9631 - loss: 0.1057 - val_categorical_accuracy: 0.8909 - val_loss: 0.2466 - learning_rate: 0.0010\n",
      "Epoch 101/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.9630 - loss: 0.1032 - val_categorical_accuracy: 0.9273 - val_loss: 0.2433 - learning_rate: 0.0010\n",
      "Epoch 102/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - categorical_accuracy: 0.9642 - loss: 0.0969 - val_categorical_accuracy: 0.9455 - val_loss: 0.2056 - learning_rate: 0.0010\n",
      "Epoch 103/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - categorical_accuracy: 0.9616 - loss: 0.1068 - val_categorical_accuracy: 0.9273 - val_loss: 0.2080 - learning_rate: 0.0010\n",
      "Epoch 104/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - categorical_accuracy: 0.9642 - loss: 0.0941 - val_categorical_accuracy: 0.9091 - val_loss: 0.2339 - learning_rate: 0.0010\n",
      "Epoch 105/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - categorical_accuracy: 0.9605 - loss: 0.1066 - val_categorical_accuracy: 0.9455 - val_loss: 0.2242 - learning_rate: 0.0010\n",
      "Epoch 106/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - categorical_accuracy: 0.9654 - loss: 0.0990 - val_categorical_accuracy: 0.9091 - val_loss: 0.2333 - learning_rate: 0.0010\n",
      "Epoch 107/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - categorical_accuracy: 0.9393 - loss: 0.1523 - val_categorical_accuracy: 0.8727 - val_loss: 0.3343 - learning_rate: 0.0010\n",
      "Epoch 108/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - categorical_accuracy: 0.9486 - loss: 0.1219 - val_categorical_accuracy: 0.9091 - val_loss: 0.2228 - learning_rate: 0.0010\n",
      "Epoch 109/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - categorical_accuracy: 0.9610 - loss: 0.0991 - val_categorical_accuracy: 0.9273 - val_loss: 0.2482 - learning_rate: 0.0010\n",
      "Epoch 110/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - categorical_accuracy: 0.9619 - loss: 0.1099 - val_categorical_accuracy: 0.8727 - val_loss: 0.3792 - learning_rate: 0.0010\n",
      "Epoch 111/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - categorical_accuracy: 0.9155 - loss: 0.2382 - val_categorical_accuracy: 0.9273 - val_loss: 0.2520 - learning_rate: 0.0010\n",
      "Epoch 112/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - categorical_accuracy: 0.9674 - loss: 0.0935 - val_categorical_accuracy: 0.8909 - val_loss: 0.2444 - learning_rate: 0.0010\n",
      "Epoch 113/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - categorical_accuracy: 0.9645 - loss: 0.1003 - val_categorical_accuracy: 0.9273 - val_loss: 0.2326 - learning_rate: 1.0000e-04\n",
      "Epoch 114/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.9774 - loss: 0.0846 - val_categorical_accuracy: 0.9636 - val_loss: 0.2287 - learning_rate: 1.0000e-04\n",
      "Epoch 115/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - categorical_accuracy: 0.9714 - loss: 0.0879 - val_categorical_accuracy: 0.9273 - val_loss: 0.2331 - learning_rate: 1.0000e-04\n",
      "Epoch 116/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - categorical_accuracy: 0.9760 - loss: 0.0858 - val_categorical_accuracy: 0.9273 - val_loss: 0.2360 - learning_rate: 1.0000e-04\n",
      "Epoch 117/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - categorical_accuracy: 0.9733 - loss: 0.0889 - val_categorical_accuracy: 0.9273 - val_loss: 0.2347 - learning_rate: 1.0000e-04\n",
      "Epoch 118/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - categorical_accuracy: 0.9789 - loss: 0.0842 - val_categorical_accuracy: 0.9273 - val_loss: 0.2249 - learning_rate: 1.0000e-04\n",
      "Epoch 119/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - categorical_accuracy: 0.9737 - loss: 0.0882 - val_categorical_accuracy: 0.9091 - val_loss: 0.2250 - learning_rate: 1.0000e-04\n",
      "Epoch 120/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - categorical_accuracy: 0.9738 - loss: 0.0811 - val_categorical_accuracy: 0.9455 - val_loss: 0.2248 - learning_rate: 1.0000e-04\n",
      "Epoch 121/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9739 - loss: 0.0850 - val_categorical_accuracy: 0.9273 - val_loss: 0.2221 - learning_rate: 1.0000e-04\n",
      "Epoch 122/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - categorical_accuracy: 0.9688 - loss: 0.0883 - val_categorical_accuracy: 0.9091 - val_loss: 0.2291 - learning_rate: 1.0000e-04\n",
      "Epoch 123/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - categorical_accuracy: 0.9797 - loss: 0.0815 - val_categorical_accuracy: 0.9091 - val_loss: 0.2261 - learning_rate: 1.0000e-05\n",
      "Epoch 124/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - categorical_accuracy: 0.9782 - loss: 0.0809 - val_categorical_accuracy: 0.9091 - val_loss: 0.2267 - learning_rate: 1.0000e-05\n",
      "Epoch 125/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - categorical_accuracy: 0.9759 - loss: 0.0927 - val_categorical_accuracy: 0.9091 - val_loss: 0.2270 - learning_rate: 1.0000e-05\n",
      "Epoch 126/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - categorical_accuracy: 0.9775 - loss: 0.0873 - val_categorical_accuracy: 0.9091 - val_loss: 0.2264 - learning_rate: 1.0000e-05\n",
      "Epoch 127/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - categorical_accuracy: 0.9765 - loss: 0.0859 - val_categorical_accuracy: 0.9273 - val_loss: 0.2261 - learning_rate: 1.0000e-05\n",
      "Epoch 128/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - categorical_accuracy: 0.9750 - loss: 0.0881 - val_categorical_accuracy: 0.9091 - val_loss: 0.2269 - learning_rate: 1.0000e-05\n",
      "Epoch 129/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9744 - loss: 0.0900 - val_categorical_accuracy: 0.9091 - val_loss: 0.2270 - learning_rate: 1.0000e-05\n",
      "Epoch 130/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - categorical_accuracy: 0.9795 - loss: 0.0809 - val_categorical_accuracy: 0.9091 - val_loss: 0.2265 - learning_rate: 1.0000e-05\n",
      "Epoch 131/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - categorical_accuracy: 0.9772 - loss: 0.0859 - val_categorical_accuracy: 0.9091 - val_loss: 0.2277 - learning_rate: 1.0000e-05\n",
      "Epoch 132/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - categorical_accuracy: 0.9787 - loss: 0.0829 - val_categorical_accuracy: 0.9091 - val_loss: 0.2273 - learning_rate: 1.0000e-05\n",
      "Epoch 133/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - categorical_accuracy: 0.9795 - loss: 0.0818 - val_categorical_accuracy: 0.9091 - val_loss: 0.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 134/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - categorical_accuracy: 0.9760 - loss: 0.0857 - val_categorical_accuracy: 0.9091 - val_loss: 0.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 135/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - categorical_accuracy: 0.9755 - loss: 0.0860 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 136/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - categorical_accuracy: 0.9763 - loss: 0.0860 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 137/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - categorical_accuracy: 0.9776 - loss: 0.0834 - val_categorical_accuracy: 0.9091 - val_loss: 0.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 138/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - categorical_accuracy: 0.9785 - loss: 0.0879 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 139/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - categorical_accuracy: 0.9775 - loss: 0.0835 - val_categorical_accuracy: 0.9091 - val_loss: 0.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 140/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - categorical_accuracy: 0.9815 - loss: 0.0817 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 141/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - categorical_accuracy: 0.9799 - loss: 0.0803 - val_categorical_accuracy: 0.9091 - val_loss: 0.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 142/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - categorical_accuracy: 0.9788 - loss: 0.0799 - val_categorical_accuracy: 0.9091 - val_loss: 0.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 143/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - categorical_accuracy: 0.9742 - loss: 0.0850 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-07\n",
      "Epoch 144/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - categorical_accuracy: 0.9756 - loss: 0.0885 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-07\n",
      "Epoch 145/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - categorical_accuracy: 0.9783 - loss: 0.0866 - val_categorical_accuracy: 0.9091 - val_loss: 0.2270 - learning_rate: 1.0000e-07\n",
      "Epoch 146/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - categorical_accuracy: 0.9808 - loss: 0.0753 - val_categorical_accuracy: 0.9091 - val_loss: 0.2270 - learning_rate: 1.0000e-07\n",
      "Epoch 147/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - categorical_accuracy: 0.9802 - loss: 0.0779 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-07\n",
      "Epoch 148/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - categorical_accuracy: 0.9778 - loss: 0.0841 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-07\n",
      "Epoch 149/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - categorical_accuracy: 0.9768 - loss: 0.0860 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-07\n",
      "Epoch 150/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - categorical_accuracy: 0.9771 - loss: 0.0877 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-07\n",
      "Epoch 151/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - categorical_accuracy: 0.9808 - loss: 0.0801 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-07\n",
      "Epoch 152/500\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - categorical_accuracy: 0.9763 - loss: 0.0872 - val_categorical_accuracy: 0.9091 - val_loss: 0.2271 - learning_rate: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "# Train best neural network\n",
    "# Rede Neural #8\n",
    "learning_rate = output[\"opt\"][\"lr\"]\n",
    "epochs = output[\"opt\"][\"epochs\"]\n",
    "batch_size = output[\"opt\"][\"batch_size\"]\n",
    "\n",
    "params = {\"hidden_units\": output[\"params\"][\"hidden_units\"], \"activation\": output[\"params\"][\"activation\"]}\n",
    "\n",
    "dataset_sizes = [1, 2, 10, 50, 100]\n",
    "\n",
    "for dataset_size in dataset_sizes:\n",
    "    dl = DataLoader(problem=\"classification\", model_name=generator_model_name, dataset_size=dataset_size)\n",
    "    datasets, minmax = dl.load_cross_validation_datasets()\n",
    "\n",
    "    train_data = datasets[\"train\"]\n",
    "    valid_data = datasets[\"valid\"]\n",
    "\n",
    "    models = []\n",
    "    for i, (train, valid) in enumerate(zip(train_data, valid_data)):\n",
    "        print(f\"Running for dataset size: {dataset_size}\")\n",
    "        train_features, train_labels = train[\"features\"], train[\"targets\"]\n",
    "        valid_features, valid_labels = valid[\"features\"], valid[\"targets\"]\n",
    "\n",
    "        features, labels = train_features.values, train_labels.values\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((features, labels)).shuffle(10000).batch(batch_size)\n",
    "\n",
    "        features, labels = valid_features.values, valid_labels.values\n",
    "        valid_ds = tf.data.Dataset.from_tensor_slices((features, labels)).batch(batch_size)\n",
    "\n",
    "        loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "            # patience 10% of epochs size\n",
    "            tf.keras.callbacks.EarlyStopping(min_delta=0.0001, patience=50),\n",
    "        ]\n",
    "        model = NeuralNetClassifier(**params)\n",
    "        model.compile(optimizer=optimizer, loss=loss_object, metrics=[accuracy])\n",
    "        h = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs,\n",
    "            validation_data=valid_ds,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,  # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        models_folder = os.path.join(\n",
    "            \"data\",\n",
    "            \"models\",\n",
    "            \"classification_with_synthetic_dataset\",\n",
    "            generator_model_name,\n",
    "            f\"{dataset_size}to1\",\n",
    "        )\n",
    "        if not os.path.isdir(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "\n",
    "        model.save(os.path.join(models_folder, f\"model_fold={i+1}.keras\"))\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models trained with synthetic dataset\n",
    "def calculate_performances_values(folder, dataset_size, generator_model):\n",
    "    dl = DataLoader(problem=\"classification\", model_name=generator_model, dataset_size=dataset_size)\n",
    "    datasets, _ = dl.load_cross_validation_datasets()\n",
    "\n",
    "    valid_data = datasets[\"valid\"]\n",
    "\n",
    "    models = [tf.keras.models.load_model(model_file) for model_file in glob(os.path.join(folder, \"*.keras\"))]\n",
    "\n",
    "    confusion_matrix_values = []\n",
    "    accuracies = []\n",
    "    sensitivities = []\n",
    "    sp_indexes = []\n",
    "\n",
    "    for valid, model in zip(valid_data, models):\n",
    "        valid_features, valid_labels = valid[\"features\"], valid[\"targets\"]\n",
    "\n",
    "        X_valid = tf.convert_to_tensor(valid_features)\n",
    "        probs = tf.convert_to_tensor(valid_labels)\n",
    "        y_valid = tf.argmax(probs, axis=1)\n",
    "\n",
    "        logits = model(X_valid)\n",
    "        probs_hat = tf.nn.softmax(logits)\n",
    "        y_valid_hat = tf.argmax(probs_hat, axis=1)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_valid, y_valid_hat)\n",
    "        confusion_matrix_values.append(cm)\n",
    "\n",
    "        # Accuracy\n",
    "        accuracies.append(np.diag(cm).sum() / cm.sum())\n",
    "\n",
    "        # Sensitivity\n",
    "        sens = np.diag(cm) / cm.sum(axis=1)\n",
    "        sensitivities.append(sens)\n",
    "\n",
    "        # SP Index\n",
    "        sp_indexes.append(np.sqrt(np.mean(sens) * gmean(sens)))\n",
    "\n",
    "    confusion_matrix_values = np.array(confusion_matrix_values)\n",
    "    accuracies = np.array(accuracies)\n",
    "    sensitivities = np.array(sensitivities)\n",
    "    sp_indexes = np.array(sp_indexes)\n",
    "\n",
    "    print(f\"Dataset {dataset_size}to1\")\n",
    "    print(\n",
    "        f\"Accuracy = {(100 * accuracies).mean():.2f} \\\\textpm {(100 * accuracies).std() / np.sqrt(K_FOLDS - 1):.2f} %\"\n",
    "    )\n",
    "\n",
    "    mean_sens = (100 * sensitivities).mean(axis=0)\n",
    "    std_err_sens = (100 * sensitivities).std(axis=0) / np.sqrt(K_FOLDS - 1)\n",
    "    print(f\"Sensitivity [V] = {mean_sens[0]:.2f} \\\\textpm {std_err_sens[0]:.2f} %\")\n",
    "    print(f\"Sensitivity [VL] = {mean_sens[1]:.2f} \\\\textpm {std_err_sens[1]:.2f} %\")\n",
    "    print(f\"Sensitivity [L] = {mean_sens[2]:.2f} \\\\textpm {std_err_sens[2]:.2f} %\")\n",
    "\n",
    "    print(\n",
    "        f\"SP Index = {(100 * sp_indexes).mean():.2f} \\\\textpm {(100 * sp_indexes).std() / np.sqrt(K_FOLDS - 1):.2f} %\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    return {\n",
    "        \"confusion_matrix\": confusion_matrix_values,\n",
    "        \"accuracies\": accuracies,\n",
    "        \"sensitivities\": sensitivities,\n",
    "        \"sp_indexes\": sp_indexes,\n",
    "    }, {\n",
    "        \"Sensitivity [V]\": f\"{mean_sens[0]:.2f} \\\\textpm {std_err_sens[0]:.2f}\",\n",
    "        \"Sensitivity [VL]\": f\"{mean_sens[1]:.2f} \\\\textpm {std_err_sens[1]:.2f}\",\n",
    "        \"Sensitivity [L]\": f\"{mean_sens[2]:.2f} \\\\textpm {std_err_sens[2]:.2f}\",\n",
    "        \"SP Index\": f\"{(100 * sp_indexes).mean():.2f} \\\\textpm {(100 * sp_indexes).std() / np.sqrt(K_FOLDS - 1):.2f}\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador: Rede Neural #8, Gerador: WGAN #11\n",
      "Dataset 1to1\n",
      "Accuracy = 80.45 \\textpm 1.55 %\n",
      "Sensitivity [V] = 90.28 \\textpm 3.50 %\n",
      "Sensitivity [VL] = 69.74 \\textpm 4.49 %\n",
      "Sensitivity [L] = 81.94 \\textpm 4.74 %\n",
      "SP Index = 80.27 \\textpm 1.56 %\n",
      "\n",
      "Dataset 2to1\n",
      "Accuracy = 85.00 \\textpm 1.87 %\n",
      "Sensitivity [V] = 87.50 \\textpm 2.66 %\n",
      "Sensitivity [VL] = 77.63 \\textpm 6.92 %\n",
      "Sensitivity [L] = 90.28 \\textpm 2.66 %\n",
      "SP Index = 84.86 \\textpm 1.97 %\n",
      "\n",
      "Dataset 10to1\n",
      "Accuracy = 93.64 \\textpm 1.17 %\n",
      "Sensitivity [V] = 91.67 \\textpm 3.59 %\n",
      "Sensitivity [VL] = 90.79 \\textpm 4.49 %\n",
      "Sensitivity [L] = 98.61 \\textpm 1.39 %\n",
      "SP Index = 93.57 \\textpm 1.16 %\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Styler.to_latex() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     33\u001b[0m     table\u001b[38;5;241m.\u001b[39mto_latex(\n\u001b[1;32m     34\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         column_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlccccc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices_dict\n\u001b[0;32m---> 48\u001b[0m wgan_indices_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWGAN #11\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mcreate_results\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(mu \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(mu\u001b[38;5;241m.\u001b[39mvalues), props, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(table)\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mapply(highlight, props\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfont-weight:bold;\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_latex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification_with_synthetic_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mperformance_indices_table_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.tex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhrules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_css\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlccccc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices_dict\n",
      "\u001b[0;31mTypeError\u001b[0m: Styler.to_latex() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "def create_results(model_name):\n",
    "    models_folder = glob(\n",
    "        os.path.join(\n",
    "            \"data\",\n",
    "            \"models\",\n",
    "            \"classification_with_synthetic_dataset\",\n",
    "            model_name,\n",
    "            \"*\",\n",
    "        )\n",
    "    )\n",
    "    models_folder = sorted(models_folder, key=lambda p: int(os.path.split(p)[-1].split(\"to\")[0]))\n",
    "    table = []\n",
    "\n",
    "    print(f\"Classificador: {classifier_model_name}, Gerador: {model_name}\")\n",
    "    indices_dict = {}\n",
    "    for folder in models_folder:\n",
    "        dataset_size = int(os.path.split(folder)[-1].split(\"to\")[0])\n",
    "        values, table_values = calculate_performances_values(folder, dataset_size, model_name)\n",
    "        indices_dict[f\"Sintético {dataset_size}x\"] = values\n",
    "        table.append(table_values)\n",
    "\n",
    "    def highlight(s, props=\"\"):\n",
    "        if s.name == \"num_params\":\n",
    "            return np.where(s == np.min(s.values), props, \"\")\n",
    "        else:\n",
    "            mu = s.apply(lambda row: float(row.split(r\" \\textpm \")[0]))\n",
    "            if s.name == \"cross_entropy\":\n",
    "                return np.where(mu == np.min(mu.values), props, \"\")\n",
    "            else:\n",
    "                return np.where(mu == np.max(mu.values), props, \"\")\n",
    "\n",
    "    table = pd.DataFrame.from_records(table).style.apply(highlight, props=\"font-weight:bold;\", axis=0)\n",
    "    table.to_latex(\n",
    "        os.path.join(\n",
    "            \"data\",\n",
    "            \"models\",\n",
    "            \"classification_with_synthetic_dataset\",\n",
    "            f\"performance_indices_table_{model_name}.tex\",\n",
    "        ),\n",
    "        hrules=True,\n",
    "        convert_css=True,\n",
    "        column_format=\"lccccc\",\n",
    "    )\n",
    "    return indices_dict\n",
    "\n",
    "\n",
    "wgan_indices_dict = create_results(model_name=\"WGAN #11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichlet_indices_dict = create_results(model_name=\"Dirichlet Estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = classifier_model_name.replace(\"#\", \"\\#\")\n",
    "\n",
    "labels = [f\"Real\", *wgan_indices_dict.keys()]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "wgan_sp_idx = np.r_[[indices[\"sp_index\"][:, model_id]], np.array([i[\"sp_indexes\"] for i in wgan_indices_dict.values()])]\n",
    "dirichlet_sp_idx = np.r_[\n",
    "    [indices[\"sp_index\"][:, model_id]], np.array([i[\"sp_indexes\"] for i in dirichlet_indices_dict.values()])\n",
    "]\n",
    "\n",
    "wgan_y = wgan_sp_idx.mean(axis=1) * 100\n",
    "wgan_y_err = (wgan_sp_idx.std(axis=1) / np.sqrt(K_FOLDS - 1)) * 100\n",
    "\n",
    "dirichlet_y = dirichlet_sp_idx.mean(axis=1) * 100\n",
    "dirichlet_y_err = (dirichlet_sp_idx.std(axis=1) / np.sqrt(K_FOLDS - 1)) * 100\n",
    "\n",
    "ax.errorbar(x, wgan_y, wgan_y_err, label=\"SP (WGAN \\#11)\", c=\"tab:blue\", **errorbar_kwargs)\n",
    "ax.errorbar(x, dirichlet_y, dirichlet_y_err, label=\"SP (Dirichlet)\", c=\"tab:orange\", **errorbar_kwargs)\n",
    "ax.errorbar([x[0]], [wgan_y[0]], [wgan_y_err[0]], label=\"SP (Real)\", c=\"black\", **errorbar_kwargs)\n",
    "ax.yaxis.grid()\n",
    "ax.set_xticks(x, labels, rotation=90, ha=\"center\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "f.tight_layout()\n",
    "plt.savefig(os.path.join(\"data\", \"images\", \"sp_index_errorbar_plot_synthetic.png\"), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, ax, model_name):\n",
    "    cm = cm / np.sum(cm, axis=2)[:, :, None]\n",
    "    cm_mean = np.mean(cm, axis=0)\n",
    "    cm_std = np.std(cm, axis=0) / np.sqrt(K_FOLDS - 1)\n",
    "\n",
    "    ms = ax.matshow(cm_mean, alpha=0.5, cmap=\"Greys\")\n",
    "    for ii in range(cm_mean.shape[0]):\n",
    "        for jj in range(cm_mean.shape[1]):\n",
    "            text = f\"{cm_mean[ii, jj] * 100:1.2f} \\\\textpm \\n {cm_std[ii, jj] * 100:1.2f} \\%\"\n",
    "            ax.text(x=jj, y=ii, s=text, va=\"center\", ha=\"center\", size=\"x-large\")\n",
    "\n",
    "    cbar = ax.figure.colorbar(ms, ax=ax, shrink=0.675, format=ticker.PercentFormatter(xmax=1))\n",
    "    ax.set_xlabel(\"Classes Estimadas\")\n",
    "    # ax.set_ylabel(\"Classes Reais\")\n",
    "    ax.set_title(model_name.replace(\"#\", \"\\#\"))\n",
    "\n",
    "    # 0: gas, 1: mix, 2: oil\n",
    "    ax.set_xticks([0, 1, 2], [\"Vapor\", \"Mistura\", \"Líquido\"])\n",
    "    ax.set_yticks([0, 1, 2], [\"Vapor\", \"Mistura\", \"Líquido\"])\n",
    "    ax.grid(False)\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "cm_real = indices[\"confusion_matrix\"][:, model_id, :, :].astype(\"int16\")\n",
    "cm_synthetic_10to1 = wgan_indices_dict[\"Sintético 10x\"][\"confusion_matrix\"].astype(\"int16\")\n",
    "plot_confusion_matrix(cm_real, axs[0], \"Dados Reais\")\n",
    "plot_confusion_matrix(cm_synthetic_10to1, axs[1], \"Sintético 10x (WGAN #11)\")\n",
    "\n",
    "f.supylabel(\"Classes Reais\")\n",
    "f.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(\"data\", \"images\", \"comparing_confusion_matrices_wgan_synthetic.png\"), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
