{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "from src.data.synthetic_gen import DataLoader\n",
    "from src.models.regression import NeuralNet\n",
    "from src.models.regression.experiments import hparams\n",
    "from src.models.regression.evaluate_models import RegressionAnalysis\n",
    "from src.models.regression.train_models import RegressionTraining\n",
    "from src.visualization.styles.formatting import errorbar_kwargs\n",
    "from src.utils import denorm\n",
    "from src.utils.constants import K_FOLDS\n",
    "\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model_name = \"Dirichlet Estimator\"\n",
    "dataset_sizes = [1, 2, 10, 50, 100]\n",
    "\n",
    "training = RegressionTraining()\n",
    "analysis = RegressionAnalysis()\n",
    "\n",
    "results = training.load_training_models()\n",
    "indices = analysis.load_performance_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training best Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Rede Neural #13, ID: 12\n",
      "    params: {'hidden_units': [128, 128, 128], 'activation': 'relu'}\n",
      "    opt:    {'lr': 0.001, 'epochs': 500, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "regressor_model_name = \"Rede Neural #13\"\n",
    "\n",
    "output = [out for out in results[\"outputs\"] if out[\"model_name\"] == regressor_model_name][0]\n",
    "model_id = [i for i, out in enumerate(results[\"outputs\"]) if out[\"model_name\"] == regressor_model_name][0]\n",
    "\n",
    "print(f\"Modelo: {output['model_name']}, ID: {model_id}\")\n",
    "print(\"    params:\", output[\"params\"])\n",
    "print(\"    opt:   \", output[\"opt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for dataset size: 100, Fold: 4\n",
      "Epoch 1/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - loss: 0.0397 - mean_absolute_error: 0.1250 - val_loss: 0.0032 - val_mean_absolute_error: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.0022 - mean_absolute_error: 0.0228 - val_loss: 0.0025 - val_mean_absolute_error: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.0016 - mean_absolute_error: 0.0186 - val_loss: 0.0015 - val_mean_absolute_error: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 9.2253e-04 - mean_absolute_error: 0.0138 - val_loss: 9.7138e-04 - val_mean_absolute_error: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 7.6083e-04 - mean_absolute_error: 0.0124 - val_loss: 9.8356e-04 - val_mean_absolute_error: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 6.2020e-04 - mean_absolute_error: 0.0109 - val_loss: 0.0014 - val_mean_absolute_error: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 5.8747e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0013 - val_mean_absolute_error: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 4.9722e-04 - mean_absolute_error: 0.0097 - val_loss: 0.0012 - val_mean_absolute_error: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 3.9117e-04 - mean_absolute_error: 0.0088 - val_loss: 8.3324e-04 - val_mean_absolute_error: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 3.6712e-04 - mean_absolute_error: 0.0084 - val_loss: 7.7208e-04 - val_mean_absolute_error: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 3.2415e-04 - mean_absolute_error: 0.0080 - val_loss: 0.0021 - val_mean_absolute_error: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 12/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 3.9081e-04 - mean_absolute_error: 0.0084 - val_loss: 8.7961e-04 - val_mean_absolute_error: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 13/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 3.4319e-04 - mean_absolute_error: 0.0084 - val_loss: 6.0008e-04 - val_mean_absolute_error: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 14/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 3.2247e-04 - mean_absolute_error: 0.0077 - val_loss: 5.5998e-04 - val_mean_absolute_error: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 15/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 2.3248e-04 - mean_absolute_error: 0.0065 - val_loss: 5.7215e-04 - val_mean_absolute_error: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 16/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 4.2792e-04 - mean_absolute_error: 0.0079 - val_loss: 7.3968e-04 - val_mean_absolute_error: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 17/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 3.4195e-04 - mean_absolute_error: 0.0071 - val_loss: 5.3323e-04 - val_mean_absolute_error: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 18/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 2.2698e-04 - mean_absolute_error: 0.0063 - val_loss: 5.2687e-04 - val_mean_absolute_error: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 19/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 1.6717e-04 - mean_absolute_error: 0.0058 - val_loss: 5.5865e-04 - val_mean_absolute_error: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 20/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 1.8037e-04 - mean_absolute_error: 0.0062 - val_loss: 0.0022 - val_mean_absolute_error: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 21/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 3.0679e-04 - mean_absolute_error: 0.0073 - val_loss: 6.1518e-04 - val_mean_absolute_error: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 22/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 2.4191e-04 - mean_absolute_error: 0.0065 - val_loss: 4.7757e-04 - val_mean_absolute_error: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 23/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 2.1131e-04 - mean_absolute_error: 0.0059 - val_loss: 5.4947e-04 - val_mean_absolute_error: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 24/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 2.5685e-04 - mean_absolute_error: 0.0065 - val_loss: 5.7773e-04 - val_mean_absolute_error: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 25/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 2.7114e-04 - mean_absolute_error: 0.0065 - val_loss: 6.3843e-04 - val_mean_absolute_error: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 26/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 1.5623e-04 - mean_absolute_error: 0.0054 - val_loss: 5.8796e-04 - val_mean_absolute_error: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 27/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 1.7927e-04 - mean_absolute_error: 0.0058 - val_loss: 6.0139e-04 - val_mean_absolute_error: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 28/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 1.8167e-04 - mean_absolute_error: 0.0058 - val_loss: 4.9079e-04 - val_mean_absolute_error: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 29/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 1.8582e-04 - mean_absolute_error: 0.0058 - val_loss: 6.6645e-04 - val_mean_absolute_error: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 30/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 1.6850e-04 - mean_absolute_error: 0.0054 - val_loss: 5.8409e-04 - val_mean_absolute_error: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 31/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 2.4105e-04 - mean_absolute_error: 0.0063 - val_loss: 5.2793e-04 - val_mean_absolute_error: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 32/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 1.3376e-04 - mean_absolute_error: 0.0050 - val_loss: 6.4908e-04 - val_mean_absolute_error: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 33/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 6.9899e-05 - mean_absolute_error: 0.0036 - val_loss: 5.3624e-04 - val_mean_absolute_error: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 34/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 6.2158e-05 - mean_absolute_error: 0.0034 - val_loss: 5.2131e-04 - val_mean_absolute_error: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 35/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 5.7862e-05 - mean_absolute_error: 0.0034 - val_loss: 5.1196e-04 - val_mean_absolute_error: 0.0085 - learning_rate: 1.0000e-04\n",
      "Epoch 36/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 5.5662e-05 - mean_absolute_error: 0.0034 - val_loss: 4.8146e-04 - val_mean_absolute_error: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 37/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 5.3638e-05 - mean_absolute_error: 0.0033 - val_loss: 5.1826e-04 - val_mean_absolute_error: 0.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 38/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 4.9764e-05 - mean_absolute_error: 0.0033 - val_loss: 5.0396e-04 - val_mean_absolute_error: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 39/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 6.2976e-05 - mean_absolute_error: 0.0033 - val_loss: 4.6239e-04 - val_mean_absolute_error: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 40/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 6.2792e-05 - mean_absolute_error: 0.0034 - val_loss: 4.8844e-04 - val_mean_absolute_error: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 41/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 5.5783e-05 - mean_absolute_error: 0.0033 - val_loss: 4.7762e-04 - val_mean_absolute_error: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 42/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 4.5712e-05 - mean_absolute_error: 0.0032 - val_loss: 5.0147e-04 - val_mean_absolute_error: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 43/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 4.3374e-05 - mean_absolute_error: 0.0031 - val_loss: 4.8964e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 44/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 4.2817e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9630e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 45/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 4.2908e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9231e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 46/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 4.0613e-05 - mean_absolute_error: 0.0030 - val_loss: 4.8729e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 47/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 4.3151e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9058e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 48/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 4.6168e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9317e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 49/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 4.8658e-05 - mean_absolute_error: 0.0031 - val_loss: 4.8889e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-05\n",
      "Epoch 50/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 4.9741e-05 - mean_absolute_error: 0.0031 - val_loss: 4.9252e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 51/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 4.7656e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9124e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 52/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 4.1738e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9684e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-05\n",
      "Epoch 53/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 4.0639e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9348e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 54/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 4.5918e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9288e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-06\n",
      "Epoch 55/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 4.1399e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9288e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 56/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 3.8476e-05 - mean_absolute_error: 0.0029 - val_loss: 4.9346e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 57/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 4.3713e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9261e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 58/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 4.2403e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9282e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 59/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 4.4348e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9260e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 60/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 4.3920e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9242e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 61/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 4.6411e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9271e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 62/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 4.1472e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9108e-04 - val_mean_absolute_error: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 63/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 4.0861e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9117e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 64/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 4.2837e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9140e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 65/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 4.1673e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9148e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 66/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 4.6815e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9163e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 67/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 4.0380e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9172e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 68/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 4.8643e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9178e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 69/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 4.4706e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9185e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 70/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 3.9310e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9190e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 71/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 4.7627e-05 - mean_absolute_error: 0.0031 - val_loss: 4.9189e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n",
      "Epoch 72/500\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 4.3318e-05 - mean_absolute_error: 0.0030 - val_loss: 4.9197e-04 - val_mean_absolute_error: 0.0078 - learning_rate: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "# Train best neural network\n",
    "# Rede Neural #8\n",
    "learning_rate = output[\"opt\"][\"lr\"]\n",
    "epochs = output[\"opt\"][\"epochs\"]\n",
    "batch_size = output[\"opt\"][\"batch_size\"]\n",
    "\n",
    "params = {\"hidden_units\": output[\"params\"][\"hidden_units\"], \"activation\": output[\"params\"][\"activation\"]}\n",
    "\n",
    "for dataset_size in dataset_sizes:\n",
    "    dl = DataLoader(problem=\"regression\", model_name=generator_model_name, dataset_size=dataset_size)\n",
    "    datasets, minmax = dl.load_cross_validation_datasets()\n",
    "\n",
    "    train_data = datasets[\"train\"]\n",
    "    valid_data = datasets[\"valid\"]\n",
    "\n",
    "    models = []\n",
    "    for i, (train, valid) in enumerate(zip(train_data, valid_data)):\n",
    "        print(f\"Running for dataset size: {dataset_size}, Fold: {i+1}\")\n",
    "        train_features, train_labels = train[\"features\"], train[\"targets\"]\n",
    "        valid_features, valid_labels = valid[\"features\"], valid[\"targets\"]\n",
    "\n",
    "        features, labels = train_features.values, train_labels.values\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((features, labels)).shuffle(10000).batch(batch_size)\n",
    "\n",
    "        features, labels = valid_features.values, valid_labels.values\n",
    "        valid_ds = tf.data.Dataset.from_tensor_slices((features, labels)).batch(batch_size)\n",
    "\n",
    "        loss_object = tf.keras.losses.MeanSquaredError()\n",
    "        mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "            # patience 10% of epochs size\n",
    "            tf.keras.callbacks.EarlyStopping(min_delta=0.0001, patience=50),\n",
    "        ]\n",
    "\n",
    "        model = NeuralNet(**params)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss_object, metrics=[mae])\n",
    "        h = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs,\n",
    "            validation_data=valid_ds,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,  # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        models_folder = os.path.join(\n",
    "            \"data\",\n",
    "            \"models\",\n",
    "            \"regression_with_synthetic_dataset\",\n",
    "            regressor_model_name,\n",
    "            generator_model_name,\n",
    "            f\"{dataset_size}to1\",\n",
    "        )\n",
    "        if not os.path.isdir(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "\n",
    "        model.save(os.path.join(models_folder, f\"model_fold={i+1}.keras\"))\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return np.abs(y_true - y_pred).mean(axis=0)\n",
    "\n",
    "def mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return np.square(y_true - y_pred).mean(axis=0)\n",
    "\n",
    "# Load saved models trained with synthetic dataset\n",
    "def calculate_performances_values(folder, dataset_size, generator_model):\n",
    "    print(f\"Dataset {dataset_size}to1\")\n",
    "    \n",
    "    dl = DataLoader(problem=\"regression\", model_name=generator_model, dataset_size=dataset_size)\n",
    "    datasets, min_max = dl.load_cross_validation_datasets()\n",
    "\n",
    "    valid_data = datasets[\"valid\"]\n",
    "    models = [tf.keras.models.load_model(model_file) for model_file in glob(os.path.join(folder, \"*.keras\"))]\n",
    "    mae, mse = [], []\n",
    "\n",
    "    for i, (valid, model) in enumerate(zip(valid_data, models)):\n",
    "        valid_features, valid_labels = valid[\"features\"], valid[\"targets\"]\n",
    "\n",
    "        X_valid = tf.convert_to_tensor(valid_features)\n",
    "        Y_valid = denorm(valid_labels.to_numpy(), *min_max[i])\n",
    "        Y_hat_valid = denorm(model(X_valid).numpy(), *min_max[i])\n",
    "    \n",
    "        mae.append(mean_absolute_error(Y_valid, Y_hat_valid))\n",
    "        mse.append(mean_squared_error(Y_valid, Y_hat_valid))\n",
    "\n",
    "    mae = np.array(mae).mean(axis=1)\n",
    "    mse = np.array(mse).mean(axis=1)\n",
    "\n",
    "    print(f\"MAE = {mae.mean():.2f} \\\\textpm {mae.std() / np.sqrt(K_FOLDS - 1):.2f}\")\n",
    "    print(f\"MSE = {mse.mean():.2f} \\\\textpm {mse.std() / np.sqrt(K_FOLDS - 1):.2f}\")\n",
    "    print()\n",
    "\n",
    "    return {\n",
    "        \"mae\": mae, \n",
    "        \"mse\": mse\n",
    "    }, {\n",
    "        \"mae\": f\"{mae.mean():.2f} \\\\textpm {mae.std():.2f}\",\n",
    "        \"mse\": f\"{mse.mean():.2f} \\\\textpm {mse.std():.2f}\"\n",
    "    }\n",
    "\n",
    "def create_results(generator_model_name, regressor_model_name):\n",
    "    models_folder = glob(\n",
    "        os.path.join(\n",
    "            \"data\",\n",
    "            \"models\",\n",
    "            \"regression_with_synthetic_dataset\",\n",
    "            regressor_model_name,\n",
    "            generator_model_name,\n",
    "            \"*\",\n",
    "        )\n",
    "    )\n",
    "    models_folder = sorted(models_folder, key=lambda p: int(os.path.split(p)[-1].split(\"to\")[0]))\n",
    "    table = []\n",
    "\n",
    "    print(f\"Regressor: {regressor_model_name}, Gerador: {generator_model_name}\")\n",
    "    indices_dict = {}\n",
    "    for folder in models_folder:\n",
    "        dataset_size = int(os.path.split(folder)[-1].split(\"to\")[0])\n",
    "        values, table_values = calculate_performances_values(folder, dataset_size, generator_model_name)\n",
    "        indices_dict[f\"Sintético {dataset_size}x\"] = values\n",
    "        table.append(table_values)\n",
    "\n",
    "    def highlight(s, props=\"\"):\n",
    "        if s.name == \"num_params\":\n",
    "            return np.where(s == np.min(s.values), props, \"\")\n",
    "        else:\n",
    "            mu = s.apply(lambda row: float(row.split(r\" \\textpm \")[0]))\n",
    "            return np.where(mu == np.min(mu.values), props, \"\")\n",
    "\n",
    "    table = pd.DataFrame.from_records(table).style.apply(highlight, props=\"font-weight:bold;\", axis=0)\n",
    "    table.to_latex(\n",
    "        os.path.join(\n",
    "            \"data\",\n",
    "            \"models\",\n",
    "            \"regression_with_synthetic_dataset\",\n",
    "            f\"performance_indices_table_{generator_model_name}_{regressor_model_name}.tex\",\n",
    "        ),\n",
    "        hrules=True,\n",
    "        convert_css=True,\n",
    "        column_format=\"lccccc\",\n",
    "    )\n",
    "    return indices_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor: Rede Neural #13, Gerador: WGAN #11\n",
      "Dataset 1to1\n",
      "MAE = 2.34 \\textpm 0.81\n",
      "MSE = 152.21 \\textpm 98.63\n",
      "\n",
      "Dataset 2to1\n",
      "MAE = 1.46 \\textpm 0.37\n",
      "MSE = 72.98 \\textpm 57.89\n",
      "\n",
      "Dataset 10to1\n",
      "MAE = 1.61 \\textpm 0.66\n",
      "MSE = 91.32 \\textpm 69.98\n",
      "\n",
      "Dataset 50to1\n",
      "MAE = 1.23 \\textpm 0.62\n",
      "MSE = 57.52 \\textpm 53.71\n",
      "\n",
      "Dataset 100to1\n",
      "MAE = 1.03 \\textpm 0.32\n",
      "MSE = 26.02 \\textpm 16.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wgan_indices_dict = create_results(\n",
    "    generator_model_name=\"WGAN #11\", \n",
    "    regressor_model_name=regressor_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor: Rede Neural #13, Gerador: Dirichlet Estimator\n",
      "Dataset 1to1\n",
      "MAE = 1.76 \\textpm 0.63\n",
      "MSE = 100.64 \\textpm 73.27\n",
      "\n",
      "Dataset 2to1\n",
      "MAE = 1.46 \\textpm 0.42\n",
      "MSE = 57.23 \\textpm 39.57\n",
      "\n",
      "Dataset 10to1\n",
      "MAE = 1.21 \\textpm 0.64\n",
      "MSE = 84.85 \\textpm 72.10\n",
      "\n",
      "Dataset 50to1\n",
      "MAE = 3.73 \\textpm 3.15\n",
      "MSE = 851.85 \\textpm 847.42\n",
      "\n",
      "Dataset 100to1\n",
      "MAE = 1.53 \\textpm 0.71\n",
      "MSE = 105.30 \\textpm 87.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dirichlet_indices_dict = create_results(\n",
    "    generator_model_name=\"Dirichlet Estimator\", \n",
    "    regressor_model_name=regressor_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.505 , 0.6713, 0.4689, 2.526 ],\n",
       "       [1.02  , 0.8641, 3.8454, 3.6121],\n",
       "       [0.8724, 0.8161, 1.8114, 2.3387],\n",
       "       [0.9893, 0.4934, 3.4905, 1.4689],\n",
       "       [0.6511, 0.3259, 0.8985, 3.0592],\n",
       "       [1.2396, 0.3116, 0.7814, 1.7996]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAFpCAYAAADgAUNWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATv0lEQVR4nO3dTU5badqA4YdSSYwaDmTW6lSrzA5I9QoadkBVraDteQ1sedTKCNk7gFpBBe8A9woI3gEnUjMuOKZHTNrfILK/UAHiY3Cgea5LQoqNX3Pyyvbt82evTCaTSQBAYt889QIAwFMTQwDSE0MA0hNDANITQwDSE0MA0hNDANITQwDSE0MA0hNDANL7ts6Nq6qKd+/exdHRURwfH881pt/vR1EUs/Htdrv2QgLAMs0dw9FoFO/fv4+qquLi4mKuMf1+PyIims1mREQMh8NotVpxcHCwwKICwHKs1P2g7sFgEPv7+3F6evrF225sbMSHDx9ma4YRESsrK+GzwQF4Tpa2z7Asy6iq6kYIp4bD4bL+LADUVmufYR1lWd56fVEUUVXVF8dfX1/H9fX17PJ///vfuLi4iFevXsXKyspjLSYA/2Mmk0n85z//iT//+c/xzTePs063tBjeZXNzc659jvv7+/H27duvsEQA/C86Pz+Pv/zlL49yX189hvMefNPtduOXX36ZXR6Px/Hdd9/F+fl5rK2tLWvxAHjmrq6u4vXr1/GnP/3p0e5zaTFsNBq3Xl9V1Z2/+9Tq6mqsrq5+dv3a2poYAvCou8yWdgBNo9GIoihu3Xe4s7OzrD8LALXVjuFdmznLspydVzjV7XZvHDk6GAxm5xwCwHMxdwynsTs4OIjRaBSdTicGg8Hs98Ph8LOT6dvtdlRVFYPBIAaDQZycnDjhHoBnp/ZJ90/l6uoq1tfXYzwe22cIkNgyeuCDugFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFITwwBSE8MAUhPDAFI79u6A/r9fhRFERERVVVFu93+4pjDw8OoqiqKooizs7Podruz+wCAp1Yrhv1+PyIims1mREQMh8NotVpxcHBw75hms3kjoP/4xz/i6OhowUUGgMe1MplMJvPeeGNjIz58+HBjrW5lZSXuu4vd3d04Pj7+4nVfcnV1Fevr6zEej2Ntba3WWABejmX0YO59hmVZzjZ1/tFwOLxzXFEUsbu7G1VVze6n0WjUXlAAWJa5N5OWZXnr9UVRzEJ3m19//TXevHkTGxsb0W63Y2tr697NqlPX19dxfX09u3x1dTXvogJALQ8+mnRzczMuLi7u/H1RFNHpdGJvby/6/X4cHR3dG8+p/f39WF9fn/28fv36oYsKALd6cAzvC2FERKfTiUajEUdHR3F2dhYXFxfx5s2bL95vt9uN8Xg8+zk/P3/oogLAreaO4V37+aqquvN30/2MOzs7s/s4PT2NoihiMBjc+/dWV1djbW3txg8ALEOtGBZFceu+w2ns/qgsy1sPuGm1WvMvIQAsWa3NpN1u98aRo4PBYHbOYcTH+E3PRYz4GMnRaPTZPsLT09PY29tbcJEB4HHVOs8w4uNJ9NPNoicnJ9Hr9Wa/Ozw8jF6vF2dnZ7PrqqqK/f39ePXq1ezI009Pwp+X8wwBiFhOD2rH8KmIIQART3zSPQC8VGIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHrf1h3Q7/ejKIqIiKiqKtrt9lzjOp1ObG1tRUTE5uZm7O3t1f3TALAUtWLY7/cjIqLZbEZExHA4jFarFQcHB3eOqaoq/v73v8e//vWvKIoiRqNRvHnzJiaTyQMWGwAez8qkRpU2Njbiw4cPszXDiIiVlZV7w9ZqtWJra+vGGuRwOIydnZ1aC3p1dRXr6+sxHo9jbW2t1lgAXo5l9GDuGJZlGVtbW5+Fb2VlJY6Pj++M28rKSpydnc3uo24Ep8QQgIjl9GDuA2jKsrz1+qIooqqqe8eMRqOoqioajUa0Wq0YDodf/HvX19dxdXV14wcAlqH2ATR/tLm5GRcXF7f+bhrDoihie3s7IiJ6vV58//33cXl5ee/97u/vx9u3bx+6eADwRQ8+teKuEH7qhx9+mP17uib5pbXDbrcb4/F49nN+fv7QRQWAW829ZthoNG69frr5s86Yoiju3Ow6tbq6Gqurq/MuHgAsbO41w0ajcWfE7jooptFoRKPR+GxMVVU31hYB4CnV2kza7XZvbN4cDAazcw4jPu4jnJ6LONXr9eK33367MWZnZ2e2DxEAnlqt8wwjPp54P938eXJyEr1eb/a7w8PD6PV6s1MpPr1+esTp77//fmPMvJxaAUDEE59n+NTEEICIJz7PEABeKjEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgvW/rDuj3+1EURUREVFUV7Xa71vjd3d04Pj6u+2cBYGlqrRn2+/2IiGg2m9FsNmN7eztardbc4weDQQyHw3pLCABLtjKZTCbz3nhjYyM+fPgwWzOMiFhZWYl57qKqqnj37l20Wq25bv9HV1dXsb6+HuPxONbW1mqPB+BlWEYP5l4zLMsyqqq6EcKpedb23r17Fz/99FOthQOAr2HufYZlWd56fVEUUVXVvWOHw2Hs7OzUWrDr6+u4vr6eXb66uqo1HgDm9eCjSTc3N+Pi4uLe21RVFY1Go9b97u/vx/r6+uzn9evXD1lMALjTg2P4pRAeHh7G3t5e7fvtdrsxHo9nP+fn54suIgDca+7NpHet2d231jcajeKHH35YaMFWV1djdXV1obEAUEetGBZFEWVZfha/u/YHXlxcxGg0mh1gc3Z2FhEfT9FoNBoLrTECwGOrdWrF9IT7ZrMZER/PGzw+Po6Dg4OI+HiQzWAwuPNE/NFoFG/evHFqBQALe9JTKyIi2u12VFUVg8EgBoNBnJyczEIY8fGo0U8vf2owGMT+/n5ERHQ6HSffA/Bs1FozfErWDAGIeAZrhgDwEokhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOmJIQDpiSEA6YkhAOl9W3dAv9+PoigiIqKqqmi323ONiYg4OzuLiIiDg4O6fxYAlqZWDKdRazabERExHA6j1WrdG7dOpxO9Xm92udVqxe7ubhwfHy+yvADw6FYmk8lk3htvbGzEhw8fZmuGERErKytx111UVRU//vhjHB0dzcaMRqN48+ZNnJ2dRaPRmHtBr66uYn19Pcbjcaytrc09DoCXZRk9mHufYVmWUVXVjRBODYfDO8e9f/8+yrKcXZ4GsKqq+ZcSAJZo7s2knwbtU0VR3Bm2oiji8vLyxnXTcH5prfD6+jqur69nl6+uruZdVACo5cFHk25ubsbFxcXct9/f34+Dg4Nb1zD/eLv19fXZz+vXrx+4pABwuwfHsE4IO51O/Pzzz7MDcO7T7XZjPB7Pfs7Pzx+ymABwp7k3k961WbOqqrkOhBkMBrG1tTVXCCMiVldXY3V1dd7FA4CFzb1m2Gg0oiiKW/cd7uzs3Dt2up9wGsKqqu7cBwkAX1utzaTdbvfGkaODweDGml5ZlrNzEadGo1GMRqPY3t6OsiyjLMs4PDyMzc3NBy46ADyOWucZRnw88X66WfTk5OTGCfWHh4fR6/VmnzRTVVV8//33tx5tWvPPOs8QgIhYTg9qx/CpiCEAEU980j0AvFRiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB6YghAemIIQHpiCEB639Yd0O/3oyiKiIioqira7fZSxgDA11JrzbDf70dERLPZjGazGdvb29FqtR59DAB8TSuTyWQy7403Njbiw4cPs7W8iIiVlZW47y4WGXObq6urWF9fj/F4HGtra7XGAvByLKMHc68ZlmUZVVXdiNrUcDh8tDEA8LXNvc+wLMtbry+KIqqqerQxU9fX13F9fT27PB6PI+LjOwIA8pp2oO4WxvvUPoDmjzY3N+Pi4uLRx+zv78fbt28/u/7169e1/hYAL9Pvv/8e6+vrj3JfD45h3RDOO6bb7cYvv/wyu1xVVfz1r3+Nf//734/2n8/g6uoqXr9+Hefn5/a1zsmcLca81WfOFjMej+O7776Lzc3NR7vPuWPYaDRuvb6qqjt/t8iYqdXV1VhdXf3s+vX1dQ+aBaytrZm3mszZYsxbfeZsMd9883inys99T41GI4qiuHU/4M7OzqONAYCvrVZWu93ujaNAB4NBNJvN2eWyLGfnFc47BgCeWq0YttvtqKoqBoNBDAaDODk5iYODg9nvh8PhjcvzjJnX6upq/POf/7x10yl3M2/1mbPFmLf6zNliljFvtU66B4CXyAd1A5CeGAKQnhgCkJ4YApCeGAKQnhgCkN6DP5v0MfX7/dnXPVVVFe12eyljXppF5y0i4uzsLCJioXM//5c99HGzu7sbx8fHS1iy523Reet0OrG1tRURHz+of29vb1mL+OwsMmeHh4ezr787OzuLbrd761fhvVRVVcW7d+/i6Oho7ufZg1sweSZ6vd6k1+vNLh8fH0+azeajj3lpFpmDdrt943Kz2Zzs7OwsZfmeo4c+bo6OjibP6Knz1Swyb5eXl5Pt7e3J5eXlZDKZTE5PT1PN3aKva9P5mkw+zuHe3t6yFvHZOT09nRwcHEx6vd5ke3t7rjGP0YJn86gsiuLGA2AymXzxSbPImJem7hxcXl5OdnZ2boyZvkCdnZ0taSmfl4c8bi4vLycHBwfpHmeTyWLz1mw2b7xITSYfX6iyWGTObntjmunN6tTR0dHcMXyMFjyLfYZlWc42CfzRp59r+tAxL82ic/D+/fsbH54+/QaRL33h8kvw0MfNu3fv4qefflrCkj1vi87b4eFh7O3tRVmWs9tl+ZD+ReesKIrY3d2dPR/Lsvzit/xk9lgteDYxvE1RFHe+QC8y5qVZZA6KoojLy8vY3t6eXTd9wGR4wj3kcTMcDtO8kP/RQ56jo9Fo9rVtrVYr1ZvV23zpsfbrr79GWZaxsbERnU7n1s985v89VgueRQzvsrm5WfvLgxcZ89LUnYP9/f04ODhItYP+j+aZs3m+hzOb++Zt+iJVFEVsb29Ho9GIXq8XP/7449dcxGfnS4+1oiii0+nE3t5e9Pv9ODo6SvMG/zHVfR181jFcJGrZQxhRbw46nU78/PPP6b9W60tzNt3cx03zPNZ++OGH2b+n79azrB3e5ktz1ul0otFoxNHRUZydncXFxUW8efPmKy3dy1G3Bc8ihne9277vnfgiY16ah87BYDCIra2tVKejLDJno9Hoxgt6Ro/5HL3rC79fmkXmbLr/a7o5vtFoxOnpaRRFEYPBYGnL+r/ssVrwbGJ41xPkrn00i4x5aR4yB9N35tM1wqqq0rxA1Z2zi4uLGA6H0e/3o9/vR6fTiYiP5zVleYFa9DnaaDQ+G1NVVYo3F4vMWVmWt+6uaLVaj714L8ZjteBZxDAiotvt3th0MhgMbmy6K8tydqL4vGMyWGTeRqNRjEaj2N7ejrIsoyzLODw8jM3Nza+23E+p7pzt7OxEu92e/UxfmNrtdqpNp4s81nq9Xvz22283xuzs7Nw4gOslW+SxNj3g6FOnp6epHmsRd2/mXFYLntWX+/b7/dlq7cnJSfR6vdnvDg8Po9frzT4xZZ4xWdSZt6qq4vvvv791h/wzeigs3SKPtYiPT7LffvstBoNBtNvt2N3dTbMlImKxeZt+mkpExO+//57uOVp3zqqqiv39/Xj16tVsH2uz2UxzgFtZlrPn2Wg0ina7HX/7299mbwaW1YJnFUMAeArPZjMpADwVMQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEID0xBCA9MQQgPTEEIL3/A+v7PmeVmtuDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = regressor_model_name.replace(\"#\", \"\\#\")\n",
    "labels = [f\"Real\", *wgan_indices_dict.keys()]\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "wgan_mae = np.r_[\n",
    "    [indices[\"mean_absolute_error\"][:, model_id, :].mean(axis=1)], \n",
    "    np.array([i[\"mae\"] for i in wgan_indices_dict.values()])\n",
    "]\n",
    "dirichlet_mae = np.r_[\n",
    "    [indices[\"mean_absolute_error\"][:, model_id].mean(axis=1)], \n",
    "    np.array([i[\"mae\"] for i in dirichlet_indices_dict.values()])\n",
    "]\n",
    "\n",
    "wgan_mae\n",
    "\n",
    "# wgan_y = wgan_mae.mean(axis=1)\n",
    "# wgan_y_err = (wgan_mae.std(axis=1) / np.sqrt(K_FOLDS - 1))\n",
    "\n",
    "# dirichlet_y = dirichlet_mae.mean(axis=1)\n",
    "# dirichlet_y_err = (dirichlet_mae.std(axis=1) / np.sqrt(K_FOLDS - 1))\n",
    "\n",
    "# ax.errorbar(x, wgan_y, wgan_y_err, label=\"SP (WGAN \\#11)\", c=\"tab:blue\", **errorbar_kwargs)\n",
    "# ax.errorbar(x, dirichlet_y, dirichlet_y_err, label=\"SP (Dirichlet)\", c=\"tab:orange\", **errorbar_kwargs)\n",
    "# ax.errorbar([x[0]], [wgan_y[0]], [wgan_y_err[0]], label=\"SP (Real)\", c=\"black\", **errorbar_kwargs)\n",
    "# ax.yaxis.grid()\n",
    "# ax.set_xticks(x, labels, rotation=90, ha=\"center\")\n",
    "# ax.legend(loc=\"lower right\")\n",
    "\n",
    "# f.tight_layout()\n",
    "# plt.savefig(os.path.join(\"data\", \"images\", f\"sp_index_errorbar_plot_synthetic_{classifier_model_name}.png\"), dpi=600)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
